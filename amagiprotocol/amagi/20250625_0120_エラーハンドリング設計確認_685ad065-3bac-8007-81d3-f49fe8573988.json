{
  "id": "685ad065-3bac-8007-81d3-f49fe8573988",
  "title": "エラーハンドリング設計確認",
  "create_time": 1750782053.425762,
  "update_time": 1750782096.581767,
  "mapping": {
    "client-created-root": {
      "id": "client-created-root",
      "message": null,
      "parent": null,
      "children": [
        "f3905e5f-c69e-4dac-95f8-a663a55a7b01"
      ]
    },
    "f3905e5f-c69e-4dac-95f8-a663a55a7b01": {
      "id": "f3905e5f-c69e-4dac-95f8-a663a55a7b01",
      "message": {
        "id": "f3905e5f-c69e-4dac-95f8-a663a55a7b01",
        "author": {
          "role": "system",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 0,
        "metadata": {
          "is_visually_hidden_from_conversation": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "client-created-root",
      "children": [
        "e6638fe1-563d-4269-8d2e-3007d34edf15"
      ]
    },
    "e6638fe1-563d-4269-8d2e-3007d34edf15": {
      "id": "e6638fe1-563d-4269-8d2e-3007d34edf15",
      "message": {
        "id": "e6638fe1-563d-4269-8d2e-3007d34edf15",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "user_editable_context",
          "user_profile": "The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: 司令\n```",
          "user_instructions": "The user provided the additional info about how they would like you to respond:\n```すべての返信に、送信日時を日本時間で付け加えてください。```"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1,
        "metadata": {
          "is_visually_hidden_from_conversation": true,
          "user_context_message_data": {
            "about_user_message": "Preferred name: 司令\n",
            "about_model_message": "すべての返信に、送信日時を日本時間で付け加えてください。"
          },
          "is_user_system_message": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "f3905e5f-c69e-4dac-95f8-a663a55a7b01",
      "children": [
        "50210e08-1dc6-4158-9644-39d12f59bb9c"
      ]
    },
    "50210e08-1dc6-4158-9644-39d12f59bb9c": {
      "id": "50210e08-1dc6-4158-9644-39d12f59bb9c",
      "message": {
        "id": "50210e08-1dc6-4158-9644-39d12f59bb9c",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1750782054.015,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "天城、相談　\n添付ファイルの\nOnError(ErrorAction.Skip)\r\n* WithRetry(3)\nの設計で鳴瀬からの質問\n実装方針の確認\n1. エラーハンドリングの適用範囲\ncsharpvar processedOrders = context.Orders\n    .OnError(ErrorAction.Skip)  // ← どの段階のエラーを対象？\n    .Map(order => ProcessOrder(order))\n    .WithRetry(3);\n\nデシリアライゼーションエラー：Kafkaメッセージ→POCOの変換失敗\nビジネスロジックエラー：ProcessOrder(order)内での例外\nKafkaコンシューマーエラー：ネットワーク切断等\n\nどの段階のエラーを対象とするか教えてください。\n2. 実装場所の設計\n現在のコードベースでは：\n\nEventSet<T>：基本的なCRUD操作\nEventSetWithServices<T>：Producer/Consumer統合\n\nエラーハンドリング機能はどちらに追加すべきでしょうか？\n3. ErrorActionの種類\ncsharppublic enum ErrorAction {\n    Skip,      // エラーレコードをスキップ\n    Retry,     // リトライ\n    DeadLetter // DLQに送信\n}\nこの理解で正しいでしょうか？他に必要なアクションはありますか？\n4. Retryの詳細仕様\n\n指数バックオフ：1秒→2秒→4秒のような遅延\n固定間隔：常に1秒間隔\n即座リトライ：遅延なし\n\nどの方式を採用しますか？\n確認後、最適な実装を提供いたします！"
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1,
        "metadata": {
          "attachments": [
            {
              "id": "file-JBa9HWksRYj1y5YJWY4By8",
              "size": 31530,
              "name": "oss_design_combined.md",
              "mime_type": "text/markdown",
              "file_token_size": 10329
            }
          ],
          "selected_sources": [],
          "selected_github_repos": [],
          "serialization_metadata": {
            "custom_symbol_offsets": []
          },
          "request_id": "954d8e17cb379d04-IAD",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "e6638fe1-563d-4269-8d2e-3007d34edf15",
      "children": [
        "e6f584c1-da3b-4044-a388-781316ff03bb"
      ]
    },
    "e6f584c1-da3b-4044-a388-781316ff03bb": {
      "id": "e6f584c1-da3b-4044-a388-781316ff03bb",
      "message": {
        "id": "e6f584c1-da3b-4044-a388-781316ff03bb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1750782065.32824,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1,
        "metadata": {
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "gpt-4o",
          "parent_id": "50210e08-1dc6-4158-9644-39d12f59bb9c",
          "request_id": "954d8e17cb379d04-IAD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "50210e08-1dc6-4158-9644-39d12f59bb9c",
      "children": [
        "9b328674-64f7-43b2-9f14-577ef17fcd0c"
      ]
    },
    "9b328674-64f7-43b2-9f14-577ef17fcd0c": {
      "id": "9b328674-64f7-43b2-9f14-577ef17fcd0c",
      "message": {
        "id": "9b328674-64f7-43b2-9f14-577ef17fcd0c",
        "author": {
          "role": "tool",
          "name": "file_search",
          "metadata": {}
        },
        "create_time": 1750782065.328454,
        "update_time": null,
        "content": {
          "content_type": "tether_browsing_display",
          "result": "",
          "summary": "",
          "assets": null,
          "tether_id": null
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 0,
        "metadata": {
          "command": "spinner",
          "status": "running",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "gpt-4o",
          "parent_id": "e6f584c1-da3b-4044-a388-781316ff03bb",
          "request_id": "954d8e17cb379d04-IAD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "e6f584c1-da3b-4044-a388-781316ff03bb",
      "children": [
        "2350f41d-d35e-46f8-9306-cc17c1a41d12"
      ]
    },
    "2350f41d-d35e-46f8-9306-cc17c1a41d12": {
      "id": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
      "message": {
        "id": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
        "author": {
          "role": "tool",
          "name": "file_search",
          "metadata": {}
        },
        "create_time": 1750782065.328547,
        "update_time": null,
        "content": {
          "content_type": "tether_quote",
          "url": "file-JBa9HWksRYj1y5YJWY4By8",
          "domain": "oss_design_combined.md",
          "text": "# OSS設計資料：統合ドキュメント\n\n## Overview\n\n### Readme\n\n﻿# KSQL Entity Framework 要件定義書\n\n## 目次 (Table of Contents)\n\n- [1. 概要](#1-概要)\n- [2. 基本原則](#2-基本原則)\n- [3. 主要コンポーネント](#3-主要コンポーネント)\n  - [3.1 トピック (Kafka Topics)](#31-トピック-kafka-topics)\n  - [3.2 ストリーム (KSQL Streams)](#32-ストリーム-ksql-streams)\n  - [3.3 テーブル (KSQL Tables)](#33-テーブル-ksql-tables)\n  - [3.4 クエリと購読](#34-クエリと購読)\n- [4. POCO (Plain Old CLR Objects) の設計](#4-poco-plain-old-clr-objects-の設計)\n  - [4.1 基本定義](#41-基本定義)\n  - [4.2 特殊型のサポート](#42-特殊型のサポート)\n- [5. プロデュース/コンシューム操作](#5-プロデュースコンシューム操作)\n  - [5.1 プロデューサー (データ送信)](#51-プロデューサー-データ送信)\n  - [5.2 コンシューマー (データ受信)](#52-コンシューマー-データ受信)\n  - [5.3 トランザクション処理](#53-トランザクション処理)\n- [6. エラー処理とデータ品質](#6-エラー処理とデータ品質)\n  - [6.1 エラー処理戦略](#61-エラー処理戦略)\n  - [6.2 デッドレターキュー](#62-デッドレターキュー)\n- [7. テーブル管理操作](#7-テーブル管理操作)\n  - [7.1 テーブル作成と更新](#71-テーブル作成と更新)\n  - [7.2 テーブルの再構築と管理](#72-テーブルの再構築と管理)\n- [8. リリース計画](#8-リリース計画)\n- [9. アーキテクチャ概要](#9-アーキテクチャ概要)\n  - [コアコンポーネント](#コアコンポーネント)\n  - [主要インターフェース](#主要インターフェース)\n  - \n## 1. 概要\n\nKSQL Entity Frameworkは、C#プログラマがEntityFrameworkライクなAPIを使用してKSQL/KafkaStreamsを操作できるようにするライブラリです。トピック中心の設計、POCOベースのクエリ定義、LINQライクなストリーム操作を特徴とします。\n\n## 2. 基本原則\n\n1. **トピック中心設計**: すべての操作はKafkaトピックを起点とする\n2. **型安全性**: C#の型システムを活用してスキーマの整合性を確保\n3. **使い慣れたAPI**: EntityFrameworkに類似したAPIデザイン\n4. **LINQサポート**: ストリーム処理をLINQクエリとして表現\n5. **段階的デプロイ**: 基本機能から高度な機能へと段階的に実装\n\n## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）\n\n本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。\nこれは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。\n\n🏷️ クラスレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Topic(\"topic-name\")]\t|Kafkaトピック名の指定（Partitions, Replicationも設定可能）\n[KsqlStream] / [KsqlTable]\t|Stream/Table の明示指定（未指定時は自動判定）\n[Table(\"name\")]\t|EF Coreとの互換性維持用（任意）\n[WindowHeartbeat(\"heartbeat-topic\")]\t|RocksDB側のウィンドウ更新確認用ハートビート設定\n\n🧩 プロパティレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Key(Order = n)]|\tKafkaのKeyに対応するプロパティ。複合キー可\n[KafkaIgnore]\t|スキーマ定義・KSQL変換から除外される\n[DecimalPrecision(precision, scale)]\t|decimal型の精度指定（例：18,4）\n[DateTimeFormat(\"format\")]\t|KSQL上でのDateTimeの文字列フォーマット\n[DefaultValue(value)]\t|定義時のデフォルト値（スキーマ定義上のみ）\n[MaxLength(n)]\t|文字列長の制約。Avroスキーマにも反映\n\n🤖 自動判定ロジック\n[Key]の有無によって [KsqlStream] or [KsqlTable] の暗黙的推定を行う\n\nNullable<T> はスキーマ上で Union<Type, null> として定義される\n\nKey属性が複数ある場合は複合キー（CompositeKey）として変換される\n\n💡 サンプル：Orderエンティティの定義\n```csharp\n[Topic(\"orders\", Partitions = 3, Replication = 1)]\n[KsqlTable]\npublic class Order\n{\n    [Key(Order = 0)]\n    public int OrderId { get; set; }\n\n    [DateTimeFormat(\"yyyy-MM-dd\")]\n    public DateTime OrderDate { get; set; }\n\n    [DecimalPrecision(18, 4)]\n    public decimal TotalAmount { get; set; }\n\n    [MaxLength(100)]\n    public string? Region { get; set; }\n\n    [KafkaIgnore]\n    public string? InternalUseOnly { get; set; }\n}\n```\n📘 設計上の方針と意図\n構成情報はすべて POCOに記述され、外部設定ファイルやFluent DSLは不要\n\n利用者は .cs ファイル上の属性のみを参照すれば動作構成を把握可能\n\n\n🔁 Fluent API の補助的活用と制限について\nPOCO属性を中心とした設計方針を採る本DSLでは、Fluent API はあくまで補助的手段として位置づけられ、以下のコンポーネントで限定的に利用可能です。\n\n🧱 1. KsqlContextBuilder（KSQL DSL全体の構成）\n```csharp\nvar context = CsharpKsqlContextBuilder.Create()\n    .UseSchemaRegistry(\"http://localhost:8081\")\n    .EnableLogging(loggerFactory)\n    .ConfigureValidation(autoRegister: true, failOnErrors: false, enablePreWarming: true)\n    .WithTimeouts(TimeSpan.FromSeconds(5))\n    .EnableDebugMode(true)\n    .Build()\n    .BuildContext<MyKsqlContext>();\n```\n主な用途：\n\nスキーマレジストリ連携\n\nログ出力の設定\n\nバリデーションやタイムアウト等の動作制御\n\n🧩 2. ModelBuilder（Entity定義時）\n```csharp\nprotected override void OnModelCreating(IModelBuilder modelBuilder)\n{\n    modelBuilder.Entity<Order>()\n        .AsTable(); // または .AsStream()\n}\n```\nPOCO属性に Stream/Table 指定がない場合のみ使用可\n\n明示的な型指定を可能にする（ただし key/topic 設定は禁止）\n\n📦 3. AvroEntityConfigurationBuilder（Avroスキーマ定義の詳細制御）\n```csharp\nconfiguration.Configure<Order>()\n    .ToTopic(\"orders\")                   // ❌ 非推奨（属性優先）\n    .HasKey(o => o.Id)                   // ❌ 非推奨\n    .WithPartitions(3)\n    .WithReplicationFactor(2)\n    .AsStream();                         // ✅ Stream/Table指定のみ許可\n```    \nこのビルダーは、Avroスキーマ生成時に高度な制御が必要な場合に限り使用される。\nただし、以下のメソッド呼び出しは設計原則違反となる。\n\n🚫 制限事項\nメソッド\t理由\n.ToTopic(\"...\")\tトピック名は [Topic] 属性で指定するため禁止\n.HasKey(...)\tキー定義は [Key] 属性に一本化されている\n.AsStream() / .AsTable()\t属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー\n\nこれらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。\n\n### 3.1 トピック (Kafka Topics)\n\n\n#### トピック定義\n```csharp\n// 属性によるマッピング\n[Topic(\"orders\", PartitionCount = 12, ReplicationFactor = 3)]\npublic class Order \n{\n    [Key]\n    public string OrderId { get; set; }\n    public string CustomerId { get; set; }\n    public decimal Amount { get; set; }\n    public DateTime OrderTime { get; set; }\n}\n\n// Fluent API\nmodelBuilder.Entity<Order>()\n    .WithPartitions(12)\n    .WithReplicationFactor(3);\n```\n\n#### トピック構成\n- パーティション設定: パーティション数、パーティショニング戦略\n- レプリケーション設定: レプリケーションファクター、ISRの最小数\n- 保持ポリシー: メッセージの保持期間、サイズ制限\n- 圧縮設定: トピックレベルの圧縮方式\n\n#### スキーマ管理\n- 自動スキーマ登録: POCOからAvroスキーマを生成し登録\n- 互換性設定: スキーマ互換性ポリシーの指定\n- スキーマ進化: スキーマバージョンの管理とマイグレーション\n\n#### トピック操作\n```csharp\n/ 型定義に基づく登録\nawait context.EnsureDeclaredAsync<Order>();\n\n// 型定義に基づく削除\nawait context.UndeclareAsync<Order>();\n```\n\n### 3.2 ストリーム (KSQL Streams)\n#### ストリーム定義の前提\n\nストリームは POCO に対して LINQ 式が適用されたときに動的に解釈され、生成される。\n\n#### 判定ルール\n\nPOCO（C#のエンティティ定義）に対してLINQ式が記述された場合、\nその型は \"ストリーム\" として解釈され、対応する CREATE STREAM 定義が自動生成されます。\n\nただし、以下のように GroupBy や Aggregate、Window を含む場合は CREATE TABLE（テーブル）として解釈されます。\n```csharp\n// ストリームとして解釈される例（AutoCommitがデフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// テーブルとして解釈される例（GroupBy を含む）\nmodelBuilder.Entity<Order>()\n    .Window(TumblingWindow.Of(TimeSpan.FromHours(1)))\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new HourlyStats \n    { \n        CustomerId = g.Key,\n        Hour = g.Window.Start,\n        OrderCount = g.Count() \n    });\n\n// 明示的にストリームとして扱う（GroupByがあっても）\nmodelBuilder.Entity<Order>()\n    .AsStream()\n    .GroupBy(o => o.Region)\n    .Select(g => new { g.Key });\n\n// 明示的にテーブルとして扱う\nmodelBuilder.Entity<Order>()\n    .AsTable()\n    .Select(o => new { o.CustomerId, o.Amount });\n```\n\nこのように modelBuilder.Entity<Order>() に対して LINQ が付くか否かで \"配信対象\"\nさらに LINQ の内容によって \"ストリーム\" か \"テーブル\" かを判別します。\n加えて、.AsStream() や .AsTable() を使用することで、意図的に解釈を上書きすることも可能です。\n\n#### コミット方式の指定\n\n購読処理（ForEachAsync）時の commit モードは、LINQ 定義末尾で明示的に設定します。\n```csharp\n// 自動コミット（デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// 手動コミットを明示\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n```\n注意：購読時の commit モードは LINQ 実行時に切り替えることはできません。定義時に確定させる必要があります。\n\n### 3.3 テーブル (KSQL Tables)\n\nこのライブラリでは、LINQ 式が GroupBy や Aggregate を含み、テーブルと判定された場合、対応するトピックは 自動的に compact モードで作成 されます。\n\n開発者はコンパクションの有無を意識せず、通常の LINQ クエリ定義だけで正しく永続化特性を持ったトピックを扱えます。\n```csharp\nvar latestOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new {\n        CustomerId = g.Key,\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n```\nこの例では CustomerId をキーとした最新の注文金額だけを保持するテーブルが作成され、その裏のトピックは compact となります。\n\n#### テーブル判定ルールと基本設計\nPOCO（C#のエンティティ定義）に対する LINQ 式の中で GroupBy, Aggregate, Window などの構文が含まれている場合、そのクエリは CREATE TABLE に相当する KSQL テーブルと解釈されます。これにより、ストリームとテーブルの判定が LINQ 構文の意味に基づいて一貫して行われます。\n\nまた、.AsTable() を明示的に呼び出すことで、意図的にテーブルとして扱うことも可能です。\n\n#### 集約操作\n```csharp\n// サマリ集計\nvar customerStats = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerStats \n    { \n        CustomerId = g.Key, \n        TotalAmount = g.Sum(o => o.Amount),\n        OrderCount = g.Count()\n    });\n\n// LATEST_BY_OFFSET\nvar latestCustomerOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerLatestOrder\n    {\n        CustomerId = g.Key,\n        LatestOrderId = g.LatestByOffset(o => o.OrderId),\n        LatestOrderTime = g.LatestByOffset(o => o.OrderTime),\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n\n// EARLIEST_BY_OFFSET\nvar firstTimeCustomers = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerFirstOrder\n    {\n        CustomerId = g.Key,\n        FirstOrderId = g.EarliestByOffset(o => o.OrderId),\n        FirstOrderTime = g.EarliestByOffset(o => o.OrderTime),\n        FirstAmount = g.EarliestByOffset(o => o.Amount)\n    });\n\n\n```\n#### テーブル結合（JOIN）\n\n```csharp\n// 単一キー結合\nvar query = from o in context.Orders\n            join c in context.Customers\n            on o.CustomerId equals c.CustomerId\n            select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 複合キー結合\nvar query2 = from o in context.Orders\n             join c in context.Customers\n             on new { o.CustomerId, o.Region } equals \n                new { c.CustomerId, c.Region }\n             select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 3テーブル結合\nvar query3 = from o in context.Orders\n             join c in context.Customers on o.CustomerId equals c.CustomerId\n             join p in context.Products on o.ProductId equals p.ProductId\n             select new {\n                 o.OrderId,\n                 c.CustomerName,\n                 p.ProductName,\n                 o.Quantity,\n                 o.Amount\n             };\n\n```\n\n### 3.4 クエリと購読\n\n#### ストリーム定義とコミット方式の指定\n```csharp\n// modelBuilder による定義（自動コミット：デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n// 自動コミットの購読処理（デフォルト）\nawait foreach (var order in context.Orders.ForEachAsync())\n{\n    Console.WriteLine($\"Received: {order.Value.OrderId}\");\n    // 自動でコミットされるため明示的な commit は不要\n}\n\n// modelBuilder による定義（手動コミット）\nmodelBuilder.Entity<HighValueOrder>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n\n// 手動コミット付きの購読処理\nawait foreach (var order in context.HighValueOrders.ForEachAsync())\n{\n    try\n    {\n        Console.WriteLine($\"Received: {order.Value.OrderId}\");\n        await order.CommitAsync();\n    }\n    catch\n    {\n        await order.NegativeAckAsync();\n    }\n}\n```\n\n## 4. POCO (Plain Old CLR Objects) の設計\n\n### 4.1 基本定義\n- シンプルなC#クラス: 特別な基底クラス不要\n- 標準的なプロパティ: 一般的な.NET型のサポート\n\n\n### 4.2 型のサポート\n\n以下はPOCOで使用可能な主なデータ型の一覧です：\n\n|データ型|説明|\n---|---\nint, long|整数型、KafkaではAvro/Protobuf経由でそのままマッピング可能\nfloat, double|浮動小数点数\ndecimal|高精度数値。[DecimalPrecision]で精度指定可能\nbool|真偽値\nstring|テキスト\nDateTime, DateTimeOffset|日時型。Kafkaへの送信時にUTC変換処理が入る\nGuid|一意識別子としてサポート\nshort|Kafkaでは int として扱われます。使用可能ですが、必要に応じて明示的なスキーマ変換を考慮してください。\nchar|Kafkaには直接の対応がなく、事実上非推奨です。1文字は string 型で表現することを推奨します。\n\n#### Decimal型の精度指定\n```csharp\n[DecimalPrecision(precision: 18, scale: 4)]\npublic decimal Amount { get; set; }\n```\n\n#### DateTime/DateTimeOffset\n```csharp\n// DateTimeOffset推奨（タイムゾーン情報保持）\npublic DateTimeOffset TransactionTime { get; set; }\n\n// または設定付きのDateTime\n[DateTimeFormat(Format = \"yyyy-MM-dd'T'HH:mm:ss.SSS\", Locale = \"en-US\")]\npublic DateTime OrderDate { get; set; }\n```\nKafkaにはタイムゾーンの概念がなく、すべての時刻はUTCとして扱われます。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。また、DateTime を使用しても、Kafka送信時には内部的に DateTimeOffset(Utc) に変換されるため、安全に運用可能です。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。\n\nこのフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。\nDateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。\nそのため、タイムゾーンを意識したビジネスロジックの記述が可能です。\n#### null許容性\n```csharp\n// C#標準の ?修飾子を使用\npublic int? OptionalQuantity { get; set; }\n```\n\n#### 数値型のデフォルト値\n```csharp\n[DefaultValue(10)]\npublic int Quantity { get; set; }\n```\n非nullableな数値プロパティ（例：int, double など）は、C#の仕様により初期化されていない場合でも自動的に 0 や 0.0 などの既定値が適用されます。Kafka送信時もこれらの値がそのまま使用されます。特別な初期化が不要なケースでは [DefaultValue] 属性は省略可能です。\n\n## 5. プロデュース操作\nこのセクションでは、Kafka にデータを送信（プロデュース）する際の基本的な操作方法とフレームワークが提供する抽象化手法について説明します。開発者は Kafka の複雑な設定を意識することなく、Entity Framework ライクな記述でストリームデータを扱うことができます。\n### 5.1 プロデューサー (データ送信)\nKafkaのリアルタイム性を維持するため、本フレームワークでは AddAsync によって即時にKafkaへ送信が行われます。\nEntity Frameworkのように SaveChangesAsync によってバッファを明示的にフラッシュする設計とは異なります。\nこのため、開発者は AddAsync を「送信操作」として扱うことを前提に実装してください。\n```csharp\n// 単一レコードのプロデュース\nawait context.Orders.AddAsync(new Order { OrderId = \"123\", Amount = 100 });\n\n```\nAddAsync を呼び出すことで、該当する Kafka トピックにイベントが送信されます。\n\n複数件のバッファリング送信や並列制御も内部で吸収されます\n\n### 5.3 トランザクション処理\nKafka は一部の操作に対して「プロデューサートランザクション」をサポートしています。ただし、ksqlDB 側ではトランザクション処理を前提としていないため、本フレームワークでは以下のような方針を採用します：\n\n明示的なトランザクション API は提供しない（例：BeginTransaction / CommitTransaction）\n\nKafka における「Exactly Once Semantics (EOS)」をサポートする構成の場合でも、アプリケーション側では操作単位の idempotency を保証してください。\n\n複数件の連続送信が必要な場合、アプリケーション側で逐次 AddAsync() を呼び出す実装で十分に高い信頼性を確保できます。\n\nこのフレームワークでは、Kafka のリアルタイムストリーム処理の思想に従い、永続化トランザクションよりも 即時性と可用性のバランスを優先しています。\n\n\n## 6. エラー処理とデータ品質\n\n### 6.1 エラー処理戦略\n```csharp\n// エラー処理ポリシーの設定\ncontext.Options.DeserializationErrorPolicy = ErrorPolicy.Skip;\n\n// エラーハンドリング付きストリーム処理\nvar processedOrders = context.Orders\n    .OnError(ErrorAction.Skip)  // エラーレコードをスキップ\n    .Map(order => ProcessOrder(order))\n    .WithRetry(3);  // 失敗時に3回リトライ\n```\n\n### 6.2 デッドレターキュー\nDLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。\nDLQ トピック名は省略可能で、省略された場合は \"{EntityName}-dlq\" の形式で自動生成されます。\n```csharp\nmodelBuilder.Entity<Order>()\n    .WithDeadLetterQueue(); \n    // トピック名は \"orders-dlq\" のように自動生成されます\n```\nDLQ を設定することで、変換や送信に失敗したデータを指定トピックへ退避可能です。\n\nDLQ に送られたメッセージは後続で再処理やモニタリングの対象となります。\n\n### 6.3 スキーマフォーマットについて\n\n本フレームワークでは、Kafka のスキーマレジストリと連携するフォーマットとして Avro のみ をサポートしています。\n\nJSON Schema は扱いません（理由：データサイズ・速度・互換性管理の観点から）\n\nPOCO から Avro スキーマは自動生成され、初回登録 or 更新時にレジストリへ登録されます\n\nスキーマレジストリの互換性設定（BACKWARD, FULL など）に応じた開発を推奨します\n\n## 7. テーブル管理操作（開発・検証用途）\n本フレームワークでは、KSQL上に定義されるストリーム／テーブルの初期化・削除を、開発・検証用途に限り API として提供します。\n\n```csharp\nawait context.EnsureTableCreatedAsync<HourlyStats>();\nawait context.DropTableAsync(\"hourly_stats\");\n```\n注意:\nこれらの操作は 開発・CI/CD 環境での利用を前提 としており、本番環境での実行は推奨されません。\n本番では modelBuilder による明示的な定義と、デプロイ時のDDL管理が基本となります。\n\n\n## 8. リリース計画\n\n### フェーズ1: 基盤構築 (v0.1-v0.3)\n- トピックおよびストリーム定義 DSL\n- POCO ベースのデータ定義とマッピング\n- プロデュース / コンシューム操作の抽象化\n- Dead Letter Queue 対応\n\n\n### フェーズ2: 高度なストリーム処理 (v0.4-v0.6)\n- LINQ ベースのウィンドウ・集約処理\n- ストリーム / テーブルの明示的切り替え\n- スキーマ進化対応の検討\n\n### フェーズ3: 高度なデータ連携 (v0.7-v0.9)\n- JOIN処理のDSL化（複合キー対応含む）\n- テーブル定義と RocksDB 前提の読み取り最適化\n- エラー通知・メトリクス・DLQ監視基盤との連携\n\n### フェーズ4: エンタープライズ機能 (v1.0+)\n- 分散トレーシングとメトリクス\n- トランザクショナルメッセージング\n- マルチクラスタサポート\n\n## 9. アーキテクチャ概要\n本フレームワークは、Kafka／ksqlDB 環境における Entity Framework ライクな操作を実現するために、以下の主要レイヤーと責務をもって構成されます。\n### 9.1 レイヤー構成\n\n```\n+------------------------------+\n| アプリケーション層           |\n|------------------------------|\n| - コンシューマ購読処理       |\n| - LINQベースのDSL記述       |\n| - POCO定義（エンティティ）   |\n+------------------------------+\n            ↓\n+------------------------------+\n| DSL定義／マッピング層        |\n|------------------------------|\n| - modelBuilder によるDSL定義 |\n| - LINQの解釈とクエリ変換     |\n| - ストリーム／テーブル区別   |\n+------------------------------+\n            ↓\n+------------------------------+\n| コード解析・モデル構築層     |\n|------------------------------|\n| - POCO構造の解析              |\n| - Avroスキーマの自動生成     |\n| - スキーマレジストリへの登録 |\n| - トピック／DLQ名の解決       |\n+------------------------------+\n            ↓\n+------------------------------+\n| Kafka連携層（プロデュース／購読）|\n|------------------------------|\n| - Kafkaへの送信（AddAsync）   |\n| - ForEachAsyncによる購読処理 |\n| - DLQへのエラールーティング   |\n+------------------------------+\n            ↓\n+------------------------------+\n| KSQL操作層                   |\n|------------------------------|\n| - CREATE STREAM/TABLE生成    |\n| - JOIN / AGGREGATE の発行    |\n| - クエリ登録と監視           |\n+------------------------------+\n            ↓\n+------------------------------+\n| RocksDBキャッシュ層（KTable backing store） |\n|------------------------------|\n| - KTable/テーブル参照時にRocksDBでローカルキャッシュ\n| - 参照クエリは極力RocksDB経由で応答（遅延低減・パフォーマンス最適化）\n+------------------------------+\n\n```\n### 9.2 フォーマットポリシー\n\n本フレームワークでは Kafka との通信において Avro のみを正式サポート しています。\n\nJSON Schema はサポート対象外です（理由：サイズ効率・速度・互換性管理の明確性）。\n\nスキーマは自動生成され、スキーマレジストリに登録されます。\n\n### 9.3 補足\n\nスキーマレジストリの接続設定や互換性ルール（BACKWARD 等）は別途構成で指定。\n\nストリーム／テーブルの定義、DLQ設定、LINQ DSL、プロデュース／購読などの責務が明確に分離されており、将来的な拡張やプラガブルアーキテクチャが可能です。\n\n #### RocksDBキャッシュ設計思想\n\n 本フレームワークでは、KSQLのテーブル（KTable）参照時に、RocksDBをバックエンドストアとして自動利用し、参照クエリのパフォーマンスを最大化しています。\n\n - 通常の`.ToList()`や`.FirstOrDefault()`などの参照はRocksDBを経由し、ksqlDBやKafka本体への都度問い合わせを避けます。\n - RocksDB層はデフォルトで有効化。キャッシュサイズや永続化設定など詳細は将来的にFluent APIで拡張予定です。\n - この設計により、「大量データ参照でもレイテンシが大幅に低減」されます。\n - 詳細なパフォーマンス設計例はFAQ・運用ガイド参照。\n\n10.4 DIコンテナと初期化タイミング\n\n本フレームワークの利用においては、KafkaDbContext は DI コンテナを通じてスコープ管理されることを想定しています。\n\nDbContext のインスタンスが解決されると、内部的に OnModelCreating() が呼ばれ、LINQベースの DSL 定義が構築・解析されます。\n\nコンストラクタは軽量であり、DSL構文の構築のみを行います。\n\nKafkaやスキーマレジストリへの接続確認・リソース作成は、以下のように明示的に EnsureKafkaReadyAsync() を呼び出して実行します：\n\n```\npublic class KafkaInitializer\n{\n    private readonly KafkaDbContext _context;\n\n    public KafkaInitializer(KafkaDbContext context)\n    {\n        _context = context;\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _context.EnsureKafkaReadyAsync();\n    }\n}\n\n```\n注意点：このタイミングで Schema Registry への通信や Kafka メタデータ取得処理が走るため、接続先が利用可能でない場合に例外が発生する可能性があります。\n\nそのため、KafkaDbContext 自体は軽量な構築とし、重い外部接続処理は明示的な初期化メソッドに切り出しています。\n\nEF と異なり Kafka OSS では「コードに基づいて Kafka 側の構造を生成する」ため、初期化を明示化することで、利用者の意図したタイミングでエラーを把握できる構造となっています。\n\nこの点を考慮し、Kafka 接続が不要な構文検証モードを別途用意することも検討されます（例：ValidateModelOnly=true オプション）。\n\nKafka接続不要な構文検証モードの価値\n\nこのモードには以下の利点があります：\n\nCI/CD での構文検証：Kafka や Schema Registry が起動していない環境でも LINQ DSL や POCO の定義が妥当かを自動チェック可能。\n\nKafka インフラ未構築でも開発可能：先に LINQ や POCO を定義し、Kafka が準備される前に開発が進行可能。\n\n安全な単体テスト：Kafka 接続なしでローカルテストが可能。\n\n学習コスト低減：Kafka 環境のセットアップを待たずに、DSL定義の学習・試行錯誤が可能。。\n\n\n## 11. Kafkaのcommit/DB commit・障害時の動作（DBエンジニア必読）\n\nKafkaのコンシューマアプリでは「オフセットcommit」と「DBのトランザクションcommit」は同じではありません。 特にDBエンジニア・テックリード層に多い勘違いとして、\\*\\*障害発生時には「前回commitしたオフセット」から“再度メッセージが流れてくる”\\*\\*という動作を理解しておく必要があります。\n\n### サンプル：障害発生時の「重複実行」イメージ\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    // 1. DBに書き込む\n    db.Save(msg.Value); // 例：OrdersテーブルにINSERT\n\n    // 2. Kafkaにオフセットcommit（\"ここまで処理済み\"を通知）\n    consumer.Commit(msg);\n}\n```\n\n#### ▼このときの「状態」例\n\n| 処理        | DB     | Kafkaオフセット | 備考                       |\n| --------- | ------ | ---------- | ------------------------ |\n| 初回実行      | 書き込み済み | commit済み   | 1回だけでOK                  |\n| commit前障害 | 書き込み済み | commit前    | **再起動後、同じmsgを再実行（DB重複）** |\n| commit後障害 | 書き込み済み | commit済み   | 以降は次のmsgから処理             |\n\n#### 【冪等化例：重複反映を防ぐパターン】\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    if (!db.Exists(msg.Key))\n    {\n        db.Save(msg.Value);\n    }\n    consumer.Commit(msg);\n}\n```\n\n- こうすることで、**再実行されてもDBは一意に保たれる**（冪等性担保）\n\n### 解説\n\n- Kafkaのcommitは「オフセット管理」でありDBのcommitとは意味が違う\n- commit前の副作用は何度も再実行される前提で設計する\n- 特にDB系テックリードは「一意反映」と誤認しやすいので**冪等設計必須**\n- こうした違いを理解せずに設計すると「二重反映」「消えたデータ」問題に直結\n\n",
          "title": "oss_design_combined.md",
          "tether_id": null
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1,
        "metadata": {
          "command": "context_stuff",
          "is_visually_hidden_from_conversation": false,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "gpt-4o",
          "parent_id": "9b328674-64f7-43b2-9f14-577ef17fcd0c",
          "request_id": "954d8e17cb379d04-IAD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "9b328674-64f7-43b2-9f14-577ef17fcd0c",
      "children": [
        "2be40021-4250-4987-8b25-5928ab475743"
      ]
    },
    "2be40021-4250-4987-8b25-5928ab475743": {
      "id": "2be40021-4250-4987-8b25-5928ab475743",
      "message": {
        "id": "2be40021-4250-4987-8b25-5928ab475743",
        "author": {
          "role": "tool",
          "name": "file_search",
          "metadata": {}
        },
        "create_time": 1750782065.328624,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "All the files uploaded by the user have been fully loaded. Searching won't provide additional information."
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1,
        "metadata": {
          "is_visually_hidden_from_conversation": false,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "gpt-4o",
          "parent_id": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
          "request_id": "954d8e17cb379d04-IAD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
      "children": [
        "20b0b312-9495-45d0-9003-645ac7f925bb"
      ]
    },
    "20b0b312-9495-45d0-9003-645ac7f925bb": {
      "id": "20b0b312-9495-45d0-9003-645ac7f925bb",
      "message": {
        "id": "20b0b312-9495-45d0-9003-645ac7f925bb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1750782053.766823,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "やあ、いらっしゃい！鳴瀬からの質問について、設計方針に基づいて以下のように回答・整理できます！\n\n---\n\n## ✅ 回答：実装方針の確認\n\n### 1. **エラーハンドリングの適用範囲**\n\n```csharp\nvar processedOrders = context.Orders\n    .OnError(ErrorAction.Skip)\n    .Map(order => ProcessOrder(order))\n    .WithRetry(3);\n```\n\n- `OnError(ErrorAction.Skip)` は **「Map前の変換エラー」および `Map` 内部の例外** に適用される。\n  - ✅ **対象エラー範囲：**\n    - POCOの **デシリアライズエラー**（Avro→POCO）\n    - `ProcessOrder()` 内の **ビジネスロジック例外**\n  - ❌ Kafkaコンシューマー層の**ネットワーク障害等**には非対応（これは `KafkaConsumer` 側の再接続・再試行機構で処理）\n\n📌 ドキュメントでも `6.1 エラー処理戦略` にてその用途が明記されている【6†oss_design_combined.md】\n\n---\n\n### 2. **実装場所の設計**\n\n- `OnError()` や `WithRetry()` は **LINQベースの処理チェーンDSL** に属する。\n- よって、**`EventSet<T>` に追加すべき。**\n  - `EventSet<T>`：LINQベースDSLの本体\n  - `EventSetWithServices<T>`：IProducer/IConsumerなどのKafka統合機能の拡張ラッパー\n\n📌 `OnError()` が `Map()` や `GroupBy()` などのDSLと同一スコープで動作する以上、**サービス依存ではなくDSLの一部**とするのが自然です。\n\n---\n\n### 3. **`ErrorAction` の種類**\n\n現在の定義：\n\n```csharp\npublic enum ErrorAction {\n    Skip,      // エラーレコードをスキップ\n    Retry,     // リトライ（WithRetry()で回数指定）\n    DeadLetter // DLQに送信\n}\n```\n\nこの設計で **現時点では十分です**。\n\n✅ 必要十分な理由：\n- Skip：テスト容易・失敗スキップ型\n- Retry：一時的障害（ネットワーク、DB）に有効\n- DeadLetter：恒久的障害（データ不整合など）への対応\n\n※今後 `LogAndContinue` や `Throw` なども検討余地はありますが、**v0.x 時点ではこれでOK**。\n\n---\n\n### 4. **Retry の詳細仕様**\n\nOSS設計方針の一貫性からみて、おすすめは：\n\n- ✅ **固定間隔：デフォルト1秒間隔（TimeSpanで調整可）**\n  - 実装例：`WithRetry(3, TimeSpan.FromSeconds(1))`\n- 将来的に `WithRetryPolicy(IRetryPolicy policy)` で指数バックオフなども可能に拡張\n\n```csharp\n// 現時点のプロトタイプ実装イメージ\npublic EventSet<T> WithRetry(int count, TimeSpan? delay = null);\n```\n\n理由：\n- Kafka/ksqlDBは **低レイテンシ環境**が前提\n- 指数バックオフは運用側の制御に移譲すべき（メトリクス連携後に再検討）\n\n---\n\n## 🔧 鳴瀬への伝達用まとめ\n\n```plaintext\n天城より設計方針の確認結果をお送りします：\n\n1. `OnError()` の対象は以下の2種です：\n   - Kafkaメッセージ → POCOのデシリアライズ時\n   - `Map()` 内での例外発生時\n   ※Kafkaネットワーク障害等は対象外（Kafka層で処理）\n\n2. 実装先は `EventSet<T>` 内に集約してください。\n   - DSL構文チェーンの一部として機能するため、Kafkaサービス依存ではありません。\n\n3. `ErrorAction` 種類（Skip/Retry/DeadLetter）は妥当です。\n   - 今後 `LogAndContinue` や `Throw` などの拡張は別途検討します。\n\n4. `WithRetry()` の仕様は：\n   - デフォルトは固定1秒間隔\n   - `WithRetry(3, TimeSpan.FromSeconds(1))` 形式で実装\n   - 将来的に指数バックオフ対応も可能な拡張構造を検討中\n\n以上、実装にお進みください。\n```\n\n---\n\n必要なら、`OnError → Map → WithRetry` の例外伝播や `ForEachAsync()` 側の `try/catch` との整合性についても補足可能です。\n\n📅 **送信日時：2025年6月25日 01:42（日本時間）**"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200002
            ]
          },
          "is_complete": true,
          "citations": [
            {
              "start_ix": 524,
              "end_ix": 550,
              "citation_format_type": "tether_og",
              "metadata": {
                "type": "file",
                "name": "oss_design_combined.md",
                "id": "file-JBa9HWksRYj1y5YJWY4By8",
                "source": "my_files",
                "text": "# OSS設計資料：統合ドキュメント\n\n## Overview\n\n### Readme\n\n﻿# KSQL Entity Framework 要件定義書\n\n## 目次 (Table of Contents)\n\n- [1. 概要](#1-概要)\n- [2. 基本原則](#2-基本原則)\n- [3. 主要コンポーネント](#3-主要コンポーネント)\n  - [3.1 トピック (Kafka Topics)](#31-トピック-kafka-topics)\n  - [3.2 ストリーム (KSQL Streams)](#32-ストリーム-ksql-streams)\n  - [3.3 テーブル (KSQL Tables)](#33-テーブル-ksql-tables)\n  - [3.4 クエリと購読](#34-クエリと購読)\n- [4. POCO (Plain Old CLR Objects) の設計](#4-poco-plain-old-clr-objects-の設計)\n  - [4.1 基本定義](#41-基本定義)\n  - [4.2 特殊型のサポート](#42-特殊型のサポート)\n- [5. プロデュース/コンシューム操作](#5-プロデュースコンシューム操作)\n  - [5.1 プロデューサー (データ送信)](#51-プロデューサー-データ送信)\n  - [5.2 コンシューマー (データ受信)](#52-コンシューマー-データ受信)\n  - [5.3 トランザクション処理](#53-トランザクション処理)\n- [6. エラー処理とデータ品質](#6-エラー処理とデータ品質)\n  - [6.1 エラー処理戦略](#61-エラー処理戦略)\n  - [6.2 デッドレターキュー](#62-デッドレターキュー)\n- [7. テーブル管理操作](#7-テーブル管理操作)\n  - [7.1 テーブル作成と更新](#71-テーブル作成と更新)\n  - [7.2 テーブルの再構築と管理](#72-テーブルの再構築と管理)\n- [8. リリース計画](#8-リリース計画)\n- [9. アーキテクチャ概要](#9-アーキテクチャ概要)\n  - [コアコンポーネント](#コアコンポーネント)\n  - [主要インターフェース](#主要インターフェース)\n  - \n## 1. 概要\n\nKSQL Entity Frameworkは、C#プログラマがEntityFrameworkライクなAPIを使用してKSQL/KafkaStreamsを操作できるようにするライブラリです。トピック中心の設計、POCOベースのクエリ定義、LINQライクなストリーム操作を特徴とします。\n\n## 2. 基本原則\n\n1. **トピック中心設計**: すべての操作はKafkaトピックを起点とする\n2. **型安全性**: C#の型システムを活用してスキーマの整合性を確保\n3. **使い慣れたAPI**: EntityFrameworkに類似したAPIデザイン\n4. **LINQサポート**: ストリーム処理をLINQクエリとして表現\n5. **段階的デプロイ**: 基本機能から高度な機能へと段階的に実装\n\n## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）\n\n本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。\nこれは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。\n\n🏷️ クラスレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Topic(\"topic-name\")]\t|Kafkaトピック名の指定（Partitions, Replicationも設定可能）\n[KsqlStream] / [KsqlTable]\t|Stream/Table の明示指定（未指定時は自動判定）\n[Table(\"name\")]\t|EF Coreとの互換性維持用（任意）\n[WindowHeartbeat(\"heartbeat-topic\")]\t|RocksDB側のウィンドウ更新確認用ハートビート設定\n\n🧩 プロパティレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Key(Order = n)]|\tKafkaのKeyに対応するプロパティ。複合キー可\n[KafkaIgnore]\t|スキーマ定義・KSQL変換から除外される\n[DecimalPrecision(precision, scale)]\t|decimal型の精度指定（例：18,4）\n[DateTimeFormat(\"format\")]\t|KSQL上でのDateTimeの文字列フォーマット\n[DefaultValue(value)]\t|定義時のデフォルト値（スキーマ定義上のみ）\n[MaxLength(n)]\t|文字列長の制約。Avroスキーマにも反映\n\n🤖 自動判定ロジック\n[Key]の有無によって [KsqlStream] or [KsqlTable] の暗黙的推定を行う\n\nNullable<T> はスキーマ上で Union<Type, null> として定義される\n\nKey属性が複数ある場合は複合キー（CompositeKey）として変換される\n\n💡 サンプル：Orderエンティティの定義\n```csharp\n[Topic(\"orders\", Partitions = 3, Replication = 1)]\n[KsqlTable]\npublic class Order\n{\n    [Key(Order = 0)]\n    public int OrderId { get; set; }\n\n    [DateTimeFormat(\"yyyy-MM-dd\")]\n    public DateTime OrderDate { get; set; }\n\n    [DecimalPrecision(18, 4)]\n    public decimal TotalAmount { get; set; }\n\n    [MaxLength(100)]\n    public string? Region { get; set; }\n\n    [KafkaIgnore]\n    public string? InternalUseOnly { get; set; }\n}\n```\n📘 設計上の方針と意図\n構成情報はすべて POCOに記述され、外部設定ファイルやFluent DSLは不要\n\n利用者は .cs ファイル上の属性のみを参照すれば動作構成を把握可能\n\n\n🔁 Fluent API の補助的活用と制限について\nPOCO属性を中心とした設計方針を採る本DSLでは、Fluent API はあくまで補助的手段として位置づけられ、以下のコンポーネントで限定的に利用可能です。\n\n🧱 1. KsqlContextBuilder（KSQL DSL全体の構成）\n```csharp\nvar context = CsharpKsqlContextBuilder.Create()\n    .UseSchemaRegistry(\"http://localhost:8081\")\n    .EnableLogging(loggerFactory)\n    .ConfigureValidation(autoRegister: true, failOnErrors: false, enablePreWarming: true)\n    .WithTimeouts(TimeSpan.FromSeconds(5))\n    .EnableDebugMode(true)\n    .Build()\n    .BuildContext<MyKsqlContext>();\n```\n主な用途：\n\nスキーマレジストリ連携\n\nログ出力の設定\n\nバリデーションやタイムアウト等の動作制御\n\n🧩 2. ModelBuilder（Entity定義時）\n```csharp\nprotected override void OnModelCreating(IModelBuilder modelBuilder)\n{\n    modelBuilder.Entity<Order>()\n        .AsTable(); // または .AsStream()\n}\n```\nPOCO属性に Stream/Table 指定がない場合のみ使用可\n\n明示的な型指定を可能にする（ただし key/topic 設定は禁止）\n\n📦 3. AvroEntityConfigurationBuilder（Avroスキーマ定義の詳細制御）\n```csharp\nconfiguration.Configure<Order>()\n    .ToTopic(\"orders\")                   // ❌ 非推奨（属性優先）\n    .HasKey(o => o.Id)                   // ❌ 非推奨\n    .WithPartitions(3)\n    .WithReplicationFactor(2)\n    .AsStream();                         // ✅ Stream/Table指定のみ許可\n```    \nこのビルダーは、Avroスキーマ生成時に高度な制御が必要な場合に限り使用される。\nただし、以下のメソッド呼び出しは設計原則違反となる。\n\n🚫 制限事項\nメソッド\t理由\n.ToTopic(\"...\")\tトピック名は [Topic] 属性で指定するため禁止\n.HasKey(...)\tキー定義は [Key] 属性に一本化されている\n.AsStream() / .AsTable()\t属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー\n\nこれらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。\n\n### 3.1 トピック (Kafka Topics)\n\n\n#### トピック定義\n```csharp\n// 属性によるマッピング\n[Topic(\"orders\", PartitionCount = 12, ReplicationFactor = 3)]\npublic class Order \n{\n    [Key]\n    public string OrderId { get; set; }\n    public string CustomerId { get; set; }\n    public decimal Amount { get; set; }\n    public DateTime OrderTime { get; set; }\n}\n\n// Fluent API\nmodelBuilder.Entity<Order>()\n    .WithPartitions(12)\n    .WithReplicationFactor(3);\n```\n\n#### トピック構成\n- パーティション設定: パーティション数、パーティショニング戦略\n- レプリケーション設定: レプリケーションファクター、ISRの最小数\n- 保持ポリシー: メッセージの保持期間、サイズ制限\n- 圧縮設定: トピックレベルの圧縮方式\n\n#### スキーマ管理\n- 自動スキーマ登録: POCOからAvroスキーマを生成し登録\n- 互換性設定: スキーマ互換性ポリシーの指定\n- スキーマ進化: スキーマバージョンの管理とマイグレーション\n\n#### トピック操作\n```csharp\n/ 型定義に基づく登録\nawait context.EnsureDeclaredAsync<Order>();\n\n// 型定義に基づく削除\nawait context.UndeclareAsync<Order>();\n```\n\n### 3.2 ストリーム (KSQL Streams)\n#### ストリーム定義の前提\n\nストリームは POCO に対して LINQ 式が適用されたときに動的に解釈され、生成される。\n\n#### 判定ルール\n\nPOCO（C#のエンティティ定義）に対してLINQ式が記述された場合、\nその型は \"ストリーム\" として解釈され、対応する CREATE STREAM 定義が自動生成されます。\n\nただし、以下のように GroupBy や Aggregate、Window を含む場合は CREATE TABLE（テーブル）として解釈されます。\n```csharp\n// ストリームとして解釈される例（AutoCommitがデフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// テーブルとして解釈される例（GroupBy を含む）\nmodelBuilder.Entity<Order>()\n    .Window(TumblingWindow.Of(TimeSpan.FromHours(1)))\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new HourlyStats \n    { \n        CustomerId = g.Key,\n        Hour = g.Window.Start,\n        OrderCount = g.Count() \n    });\n\n// 明示的にストリームとして扱う（GroupByがあっても）\nmodelBuilder.Entity<Order>()\n    .AsStream()\n    .GroupBy(o => o.Region)\n    .Select(g => new { g.Key });\n\n// 明示的にテーブルとして扱う\nmodelBuilder.Entity<Order>()\n    .AsTable()\n    .Select(o => new { o.CustomerId, o.Amount });\n```\n\nこのように modelBuilder.Entity<Order>() に対して LINQ が付くか否かで \"配信対象\"\nさらに LINQ の内容によって \"ストリーム\" か \"テーブル\" かを判別します。\n加えて、.AsStream() や .AsTable() を使用することで、意図的に解釈を上書きすることも可能です。\n\n#### コミット方式の指定\n\n購読処理（ForEachAsync）時の commit モードは、LINQ 定義末尾で明示的に設定します。\n```csharp\n// 自動コミット（デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// 手動コミットを明示\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n```\n注意：購読時の commit モードは LINQ 実行時に切り替えることはできません。定義時に確定させる必要があります。\n\n### 3.3 テーブル (KSQL Tables)\n\nこのライブラリでは、LINQ 式が GroupBy や Aggregate を含み、テーブルと判定された場合、対応するトピックは 自動的に compact モードで作成 されます。\n\n開発者はコンパクションの有無を意識せず、通常の LINQ クエリ定義だけで正しく永続化特性を持ったトピックを扱えます。\n```csharp\nvar latestOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new {\n        CustomerId = g.Key,\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n```\nこの例では CustomerId をキーとした最新の注文金額だけを保持するテーブルが作成され、その裏のトピックは compact となります。\n\n#### テーブル判定ルールと基本設計\nPOCO（C#のエンティティ定義）に対する LINQ 式の中で GroupBy, Aggregate, Window などの構文が含まれている場合、そのクエリは CREATE TABLE に相当する KSQL テーブルと解釈されます。これにより、ストリームとテーブルの判定が LINQ 構文の意味に基づいて一貫して行われます。\n\nまた、.AsTable() を明示的に呼び出すことで、意図的にテーブルとして扱うことも可能です。\n\n#### 集約操作\n```csharp\n// サマリ集計\nvar customerStats = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerStats \n    { \n        CustomerId = g.Key, \n        TotalAmount = g.Sum(o => o.Amount),\n        OrderCount = g.Count()\n    });\n\n// LATEST_BY_OFFSET\nvar latestCustomerOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerLatestOrder\n    {\n        CustomerId = g.Key,\n        LatestOrderId = g.LatestByOffset(o => o.OrderId),\n        LatestOrderTime = g.LatestByOffset(o => o.OrderTime),\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n\n// EARLIEST_BY_OFFSET\nvar firstTimeCustomers = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerFirstOrder\n    {\n        CustomerId = g.Key,\n        FirstOrderId = g.EarliestByOffset(o => o.OrderId),\n        FirstOrderTime = g.EarliestByOffset(o => o.OrderTime),\n        FirstAmount = g.EarliestByOffset(o => o.Amount)\n    });\n\n\n```\n#### テーブル結合（JOIN）\n\n```csharp\n// 単一キー結合\nvar query = from o in context.Orders\n            join c in context.Customers\n            on o.CustomerId equals c.CustomerId\n            select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 複合キー結合\nvar query2 = from o in context.Orders\n             join c in context.Customers\n             on new { o.CustomerId, o.Region } equals \n                new { c.CustomerId, c.Region }\n             select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 3テーブル結合\nvar query3 = from o in context.Orders\n             join c in context.Customers on o.CustomerId equals c.CustomerId\n             join p in context.Products on o.ProductId equals p.ProductId\n             select new {\n                 o.OrderId,\n                 c.CustomerName,\n                 p.ProductName,\n                 o.Quantity,\n                 o.Amount\n             };\n\n```\n\n### 3.4 クエリと購読\n\n#### ストリーム定義とコミット方式の指定\n```csharp\n// modelBuilder による定義（自動コミット：デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n// 自動コミットの購読処理（デフォルト）\nawait foreach (var order in context.Orders.ForEachAsync())\n{\n    Console.WriteLine($\"Received: {order.Value.OrderId}\");\n    // 自動でコミットされるため明示的な commit は不要\n}\n\n// modelBuilder による定義（手動コミット）\nmodelBuilder.Entity<HighValueOrder>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n\n// 手動コミット付きの購読処理\nawait foreach (var order in context.HighValueOrders.ForEachAsync())\n{\n    try\n    {\n        Console.WriteLine($\"Received: {order.Value.OrderId}\");\n        await order.CommitAsync();\n    }\n    catch\n    {\n        await order.NegativeAckAsync();\n    }\n}\n```\n\n## 4. POCO (Plain Old CLR Objects) の設計\n\n### 4.1 基本定義\n- シンプルなC#クラス: 特別な基底クラス不要\n- 標準的なプロパティ: 一般的な.NET型のサポート\n\n\n### 4.2 型のサポート\n\n以下はPOCOで使用可能な主なデータ型の一覧です：\n\n|データ型|説明|\n---|---\nint, long|整数型、KafkaではAvro/Protobuf経由でそのままマッピング可能\nfloat, double|浮動小数点数\ndecimal|高精度数値。[DecimalPrecision]で精度指定可能\nbool|真偽値\nstring|テキスト\nDateTime, DateTimeOffset|日時型。Kafkaへの送信時にUTC変換処理が入る\nGuid|一意識別子としてサポート\nshort|Kafkaでは int として扱われます。使用可能ですが、必要に応じて明示的なスキーマ変換を考慮してください。\nchar|Kafkaには直接の対応がなく、事実上非推奨です。1文字は string 型で表現することを推奨します。\n\n#### Decimal型の精度指定\n```csharp\n[DecimalPrecision(precision: 18, scale: 4)]\npublic decimal Amount { get; set; }\n```\n\n#### DateTime/DateTimeOffset\n```csharp\n// DateTimeOffset推奨（タイムゾーン情報保持）\npublic DateTimeOffset TransactionTime { get; set; }\n\n// または設定付きのDateTime\n[DateTimeFormat(Format = \"yyyy-MM-dd'T'HH:mm:ss.SSS\", Locale = \"en-US\")]\npublic DateTime OrderDate { get; set; }\n```\nKafkaにはタイムゾーンの概念がなく、すべての時刻はUTCとして扱われます。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。また、DateTime を使用しても、Kafka送信時には内部的に DateTimeOffset(Utc) に変換されるため、安全に運用可能です。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。\n\nこのフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。\nDateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。\nそのため、タイムゾーンを意識したビジネスロジックの記述が可能です。\n#### null許容性\n```csharp\n// C#標準の ?修飾子を使用\npublic int? OptionalQuantity { get; set; }\n```\n\n#### 数値型のデフォルト値\n```csharp\n[DefaultValue(10)]\npublic int Quantity { get; set; }\n```\n非nullableな数値プロパティ（例：int, double など）は、C#の仕様により初期化されていない場合でも自動的に 0 や 0.0 などの既定値が適用されます。Kafka送信時もこれらの値がそのまま使用されます。特別な初期化が不要なケースでは [DefaultValue] 属性は省略可能です。\n\n## 5. プロデュース操作\nこのセクションでは、Kafka にデータを送信（プロデュース）する際の基本的な操作方法とフレームワークが提供する抽象化手法について説明します。開発者は Kafka の複雑な設定を意識することなく、Entity Framework ライクな記述でストリームデータを扱うことができます。\n### 5.1 プロデューサー (データ送信)\nKafkaのリアルタイム性を維持するため、本フレームワークでは AddAsync によって即時にKafkaへ送信が行われます。\nEntity Frameworkのように SaveChangesAsync によってバッファを明示的にフラッシュする設計とは異なります。\nこのため、開発者は AddAsync を「送信操作」として扱うことを前提に実装してください。\n```csharp\n// 単一レコードのプロデュース\nawait context.Orders.AddAsync(new Order { OrderId = \"123\", Amount = 100 });\n\n```\nAddAsync を呼び出すことで、該当する Kafka トピックにイベントが送信されます。\n\n複数件のバッファリング送信や並列制御も内部で吸収されます\n\n### 5.3 トランザクション処理\nKafka は一部の操作に対して「プロデューサートランザクション」をサポートしています。ただし、ksqlDB 側ではトランザクション処理を前提としていないため、本フレームワークでは以下のような方針を採用します：\n\n明示的なトランザクション API は提供しない（例：BeginTransaction / CommitTransaction）\n\nKafka における「Exactly Once Semantics (EOS)」をサポートする構成の場合でも、アプリケーション側では操作単位の idempotency を保証してください。\n\n複数件の連続送信が必要な場合、アプリケーション側で逐次 AddAsync() を呼び出す実装で十分に高い信頼性を確保できます。\n\nこのフレームワークでは、Kafka のリアルタイムストリーム処理の思想に従い、永続化トランザクションよりも 即時性と可用性のバランスを優先しています。\n\n\n## 6. エラー処理とデータ品質\n\n### 6.1 エラー処理戦略\n```csharp\n// エラー処理ポリシーの設定\ncontext.Options.DeserializationErrorPolicy = ErrorPolicy.Skip;\n\n// エラーハンドリング付きストリーム処理\nvar processedOrders = context.Orders\n    .OnError(ErrorAction.Skip)  // エラーレコードをスキップ\n    .Map(order => ProcessOrder(order))\n    .WithRetry(3);  // 失敗時に3回リトライ\n```\n\n### 6.2 デッドレターキュー\nDLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。\nDLQ トピック名は省略可能で、省略された場合は \"{EntityName}-dlq\" の形式で自動生成されます。\n```csharp\nmodelBuilder.Entity<Order>()\n    .WithDeadLetterQueue(); \n    // トピック名は \"orders-dlq\" のように自動生成されます\n```\nDLQ を設定することで、変換や送信に失敗したデータを指定トピックへ退避可能です。\n\nDLQ に送られたメッセージは後続で再処理やモニタリングの対象となります。\n\n### 6.3 スキーマフォーマットについて\n\n本フレームワークでは、Kafka のスキーマレジストリと連携するフォーマットとして Avro のみ をサポートしています。\n\nJSON Schema は扱いません（理由：データサイズ・速度・互換性管理の観点から）\n\nPOCO から Avro スキーマは自動生成され、初回登録 or 更新時にレジストリへ登録されます\n\nスキーマレジストリの互換性設定（BACKWARD, FULL など）に応じた開発を推奨します\n\n## 7. テーブル管理操作（開発・検証用途）\n本フレームワークでは、KSQL上に定義されるストリーム／テーブルの初期化・削除を、開発・検証用途に限り API として提供します。\n\n```csharp\nawait context.EnsureTableCreatedAsync<HourlyStats>();\nawait context.DropTableAsync(\"hourly_stats\");\n```\n注意:\nこれらの操作は 開発・CI/CD 環境での利用を前提 としており、本番環境での実行は推奨されません。\n本番では modelBuilder による明示的な定義と、デプロイ時のDDL管理が基本となります。\n\n\n## 8. リリース計画\n\n### フェーズ1: 基盤構築 (v0.1-v0.3)\n- トピックおよびストリーム定義 DSL\n- POCO ベースのデータ定義とマッピング\n- プロデュース / コンシューム操作の抽象化\n- Dead Letter Queue 対応\n\n\n### フェーズ2: 高度なストリーム処理 (v0.4-v0.6)\n- LINQ ベースのウィンドウ・集約処理\n- ストリーム / テーブルの明示的切り替え\n- スキーマ進化対応の検討\n\n### フェーズ3: 高度なデータ連携 (v0.7-v0.9)\n- JOIN処理のDSL化（複合キー対応含む）\n- テーブル定義と RocksDB 前提の読み取り最適化\n- エラー通知・メトリクス・DLQ監視基盤との連携\n\n### フェーズ4: エンタープライズ機能 (v1.0+)\n- 分散トレーシングとメトリクス\n- トランザクショナルメッセージング\n- マルチクラスタサポート\n\n## 9. アーキテクチャ概要\n本フレームワークは、Kafka／ksqlDB 環境における Entity Framework ライクな操作を実現するために、以下の主要レイヤーと責務をもって構成されます。\n### 9.1 レイヤー構成\n\n```\n+------------------------------+\n| アプリケーション層           |\n|------------------------------|\n| - コンシューマ購読処理       |\n| - LINQベースのDSL記述       |\n| - POCO定義（エンティティ）   |\n+------------------------------+\n            ↓\n+------------------------------+\n| DSL定義／マッピング層        |\n|------------------------------|\n| - modelBuilder によるDSL定義 |\n| - LINQの解釈とクエリ変換     |\n| - ストリーム／テーブル区別   |\n+------------------------------+\n            ↓\n+------------------------------+\n| コード解析・モデル構築層     |\n|------------------------------|\n| - POCO構造の解析              |\n| - Avroスキーマの自動生成     |\n| - スキーマレジストリへの登録 |\n| - トピック／DLQ名の解決       |\n+------------------------------+\n            ↓\n+------------------------------+\n| Kafka連携層（プロデュース／購読）|\n|------------------------------|\n| - Kafkaへの送信（AddAsync）   |\n| - ForEachAsyncによる購読処理 |\n| - DLQへのエラールーティング   |\n+------------------------------+\n            ↓\n+------------------------------+\n| KSQL操作層                   |\n|------------------------------|\n| - CREATE STREAM/TABLE生成    |\n| - JOIN / AGGREGATE の発行    |\n| - クエリ登録と監視           |\n+------------------------------+\n            ↓\n+------------------------------+\n| RocksDBキャッシュ層（KTable backing store） |\n|------------------------------|\n| - KTable/テーブル参照時にRocksDBでローカルキャッシュ\n| - 参照クエリは極力RocksDB経由で応答（遅延低減・パフォーマンス最適化）\n+------------------------------+\n\n```\n### 9.2 フォーマットポリシー\n\n本フレームワークでは Kafka との通信において Avro のみを正式サポート しています。\n\nJSON Schema はサポート対象外です（理由：サイズ効率・速度・互換性管理の明確性）。\n\nスキーマは自動生成され、スキーマレジストリに登録されます。\n\n### 9.3 補足\n\nスキーマレジストリの接続設定や互換性ルール（BACKWARD 等）は別途構成で指定。\n\nストリーム／テーブルの定義、DLQ設定、LINQ DSL、プロデュース／購読などの責務が明確に分離されており、将来的な拡張やプラガブルアーキテクチャが可能です。\n\n #### RocksDBキャッシュ設計思想\n\n 本フレームワークでは、KSQLのテーブル（KTable）参照時に、RocksDBをバックエンドストアとして自動利用し、参照クエリのパフォーマンスを最大化しています。\n\n - 通常の`.ToList()`や`.FirstOrDefault()`などの参照はRocksDBを経由し、ksqlDBやKafka本体への都度問い合わせを避けます。\n - RocksDB層はデフォルトで有効化。キャッシュサイズや永続化設定など詳細は将来的にFluent APIで拡張予定です。\n - この設計により、「大量データ参照でもレイテンシが大幅に低減」されます。\n - 詳細なパフォーマンス設計例はFAQ・運用ガイド参照。\n\n10.4 DIコンテナと初期化タイミング\n\n本フレームワークの利用においては、KafkaDbContext は DI コンテナを通じてスコープ管理されることを想定しています。\n\nDbContext のインスタンスが解決されると、内部的に OnModelCreating() が呼ばれ、LINQベースの DSL 定義が構築・解析されます。\n\nコンストラクタは軽量であり、DSL構文の構築のみを行います。\n\nKafkaやスキーマレジストリへの接続確認・リソース作成は、以下のように明示的に EnsureKafkaReadyAsync() を呼び出して実行します：\n\n```\npublic class KafkaInitializer\n{\n    private readonly KafkaDbContext _context;\n\n    public KafkaInitializer(KafkaDbContext context)\n    {\n        _context = context;\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _context.EnsureKafkaReadyAsync();\n    }\n}\n\n```\n注意点：このタイミングで Schema Registry への通信や Kafka メタデータ取得処理が走るため、接続先が利用可能でない場合に例外が発生する可能性があります。\n\nそのため、KafkaDbContext 自体は軽量な構築とし、重い外部接続処理は明示的な初期化メソッドに切り出しています。\n\nEF と異なり Kafka OSS では「コードに基づいて Kafka 側の構造を生成する」ため、初期化を明示化することで、利用者の意図したタイミングでエラーを把握できる構造となっています。\n\nこの点を考慮し、Kafka 接続が不要な構文検証モードを別途用意することも検討されます（例：ValidateModelOnly=true オプション）。\n\nKafka接続不要な構文検証モードの価値\n\nこのモードには以下の利点があります：\n\nCI/CD での構文検証：Kafka や Schema Registry が起動していない環境でも LINQ DSL や POCO の定義が妥当かを自動チェック可能。\n\nKafka インフラ未構築でも開発可能：先に LINQ や POCO を定義し、Kafka が準備される前に開発が進行可能。\n\n安全な単体テスト：Kafka 接続なしでローカルテストが可能。\n\n学習コスト低減：Kafka 環境のセットアップを待たずに、DSL定義の学習・試行錯誤が可能。。\n\n\n## 11. Kafkaのcommit/DB commit・障害時の動作（DBエンジニア必読）\n\nKafkaのコンシューマアプリでは「オフセットcommit」と「DBのトランザクションcommit」は同じではありません。 特にDBエンジニア・テックリード層に多い勘違いとして、\\*\\*障害発生時には「前回commitしたオフセット」から“再度メッセージが流れてくる”\\*\\*という動作を理解しておく必要があります。\n\n### サンプル：障害発生時の「重複実行」イメージ\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    // 1. DBに書き込む\n    db.Save(msg.Value); // 例：OrdersテーブルにINSERT\n\n    // 2. Kafkaにオフセットcommit（\"ここまで処理済み\"を通知）\n    consumer.Commit(msg);\n}\n```\n\n#### ▼このときの「状態」例\n\n| 処理        | DB     | Kafkaオフセット | 備考                       |\n| --------- | ------ | ---------- | ------------------------ |\n| 初回実行      | 書き込み済み | commit済み   | 1回だけでOK                  |\n| commit前障害 | 書き込み済み | commit前    | **再起動後、同じmsgを再実行（DB重複）** |\n| commit後障害 | 書き込み済み | commit済み   | 以降は次のmsgから処理             |\n\n#### 【冪等化例：重複反映を防ぐパターン】\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    if (!db.Exists(msg.Key))\n    {\n        db.Save(msg.Value);\n    }\n    consumer.Commit(msg);\n}\n```\n\n- こうすることで、**再実行されてもDBは一意に保たれる**（冪等性担保）\n\n### 解説\n\n- Kafkaのcommitは「オフセット管理」でありDBのcommitとは意味が違う\n- commit前の副作用は何度も再実行される前提で設計する\n- 特にDB系テックリードは「一意反映」と誤認しやすいので**冪等設計必須**\n- こうした違いを理解せずに設計すると「二重反映」「消えたデータ」問題に直結\n\n",
                "extra": {
                  "cited_message_idx": 6,
                  "cited_message_id": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
                  "search_result_idx": null,
                  "evidence_text": "oss_design_combined.md",
                  "cloud_doc_url": null
                }
              }
            }
          ],
          "content_references": [
            {
              "matched_text": "【6†oss_design_combined.md】",
              "start_idx": 524,
              "end_idx": 550,
              "alt": null,
              "type": "file",
              "name": "oss_design_combined.md",
              "id": "file-JBa9HWksRYj1y5YJWY4By8",
              "source": "my_files",
              "snippet": "# OSS設計資料：統合ドキュメント\n\n## Overview\n\n### Readme\n\n﻿# KSQL Entity Framework 要件定義書\n\n## 目次 (Table of Contents)\n\n- [1. 概要](#1-概要)\n- [2. 基本原則](#2-基本原則)\n- [3. 主要コンポーネント](#3-主要コンポーネント)\n  - [3.1 トピック (Kafka Topics)](#31-トピック-kafka-topics)\n  - [3.2 ストリーム (KSQL Streams)](#32-ストリーム-ksql-streams)\n  - [3.3 テーブル (KSQL Tables)](#33-テーブル-ksql-tables)\n  - [3.4 クエリと購読](#34-クエリと購読)\n- [4. POCO (Plain Old CLR Objects) の設計](#4-poco-plain-old-clr-objects-の設計)\n  - [4.1 基本定義](#41-基本定義)\n  - [4.2 特殊型のサポート](#42-特殊型のサポート)\n- [5. プロデュース/コンシューム操作](#5-プロデュースコンシューム操作)\n  - [5.1 プロデューサー (データ送信)](#51-プロデューサー-データ送信)\n  - [5.2 コンシューマー (データ受信)](#52-コンシューマー-データ受信)\n  - [5.3 トランザクション処理](#53-トランザクション処理)\n- [6. エラー処理とデータ品質](#6-エラー処理とデータ品質)\n  - [6.1 エラー処理戦略](#61-エラー処理戦略)\n  - [6.2 デッドレターキュー](#62-デッドレターキュー)\n- [7. テーブル管理操作](#7-テーブル管理操作)\n  - [7.1 テーブル作成と更新](#71-テーブル作成と更新)\n  - [7.2 テーブルの再構築と管理](#72-テーブルの再構築と管理)\n- [8. リリース計画](#8-リリース計画)\n- [9. アーキテクチャ概要](#9-アーキテクチャ概要)\n  - [コアコンポーネント](#コアコンポーネント)\n  - [主要インターフェース](#主要インターフェース)\n  - \n## 1. 概要\n\nKSQL Entity Frameworkは、C#プログラマがEntityFrameworkライクなAPIを使用してKSQL/KafkaStreamsを操作できるようにするライブラリです。トピック中心の設計、POCOベースのクエリ定義、LINQライクなストリーム操作を特徴とします。\n\n## 2. 基本原則\n\n1. **トピック中心設計**: すべての操作はKafkaトピックを起点とする\n2. **型安全性**: C#の型システムを活用してスキーマの整合性を確保\n3. **使い慣れたAPI**: EntityFrameworkに類似したAPIデザイン\n4. **LINQサポート**: ストリーム処理をLINQクエリとして表現\n5. **段階的デプロイ**: 基本機能から高度な機能へと段階的に実装\n\n## 3. POCO属性ベースDSL設計ルール（Fluent APIの排除方針）\n\n本OSSでは、Kafka/KSQLの設定をすべてPOCOクラスの属性で定義する方式を採用する。\nこれは、Fluent APIを用いたDSL記述の柔軟性と引き換えに、「構成がPOCOに集約されている」という明快さを重視した設計方針である。\n\n🏷️ クラスレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Topic(\"topic-name\")]\t|Kafkaトピック名の指定（Partitions, Replicationも設定可能）\n[KsqlStream] / [KsqlTable]\t|Stream/Table の明示指定（未指定時は自動判定）\n[Table(\"name\")]\t|EF Coreとの互換性維持用（任意）\n[WindowHeartbeat(\"heartbeat-topic\")]\t|RocksDB側のウィンドウ更新確認用ハートビート設定\n\n🧩 プロパティレベル属性一覧\n|属性名\t|説明|\n|---|---|\n[Key(Order = n)]|\tKafkaのKeyに対応するプロパティ。複合キー可\n[KafkaIgnore]\t|スキーマ定義・KSQL変換から除外される\n[DecimalPrecision(precision, scale)]\t|decimal型の精度指定（例：18,4）\n[DateTimeFormat(\"format\")]\t|KSQL上でのDateTimeの文字列フォーマット\n[DefaultValue(value)]\t|定義時のデフォルト値（スキーマ定義上のみ）\n[MaxLength(n)]\t|文字列長の制約。Avroスキーマにも反映\n\n🤖 自動判定ロジック\n[Key]の有無によって [KsqlStream] or [KsqlTable] の暗黙的推定を行う\n\nNullable<T> はスキーマ上で Union<Type, null> として定義される\n\nKey属性が複数ある場合は複合キー（CompositeKey）として変換される\n\n💡 サンプル：Orderエンティティの定義\n```csharp\n[Topic(\"orders\", Partitions = 3, Replication = 1)]\n[KsqlTable]\npublic class Order\n{\n    [Key(Order = 0)]\n    public int OrderId { get; set; }\n\n    [DateTimeFormat(\"yyyy-MM-dd\")]\n    public DateTime OrderDate { get; set; }\n\n    [DecimalPrecision(18, 4)]\n    public decimal TotalAmount { get; set; }\n\n    [MaxLength(100)]\n    public string? Region { get; set; }\n\n    [KafkaIgnore]\n    public string? InternalUseOnly { get; set; }\n}\n```\n📘 設計上の方針と意図\n構成情報はすべて POCOに記述され、外部設定ファイルやFluent DSLは不要\n\n利用者は .cs ファイル上の属性のみを参照すれば動作構成を把握可能\n\n\n🔁 Fluent API の補助的活用と制限について\nPOCO属性を中心とした設計方針を採る本DSLでは、Fluent API はあくまで補助的手段として位置づけられ、以下のコンポーネントで限定的に利用可能です。\n\n🧱 1. KsqlContextBuilder（KSQL DSL全体の構成）\n```csharp\nvar context = CsharpKsqlContextBuilder.Create()\n    .UseSchemaRegistry(\"http://localhost:8081\")\n    .EnableLogging(loggerFactory)\n    .ConfigureValidation(autoRegister: true, failOnErrors: false, enablePreWarming: true)\n    .WithTimeouts(TimeSpan.FromSeconds(5))\n    .EnableDebugMode(true)\n    .Build()\n    .BuildContext<MyKsqlContext>();\n```\n主な用途：\n\nスキーマレジストリ連携\n\nログ出力の設定\n\nバリデーションやタイムアウト等の動作制御\n\n🧩 2. ModelBuilder（Entity定義時）\n```csharp\nprotected override void OnModelCreating(IModelBuilder modelBuilder)\n{\n    modelBuilder.Entity<Order>()\n        .AsTable(); // または .AsStream()\n}\n```\nPOCO属性に Stream/Table 指定がない場合のみ使用可\n\n明示的な型指定を可能にする（ただし key/topic 設定は禁止）\n\n📦 3. AvroEntityConfigurationBuilder（Avroスキーマ定義の詳細制御）\n```csharp\nconfiguration.Configure<Order>()\n    .ToTopic(\"orders\")                   // ❌ 非推奨（属性優先）\n    .HasKey(o => o.Id)                   // ❌ 非推奨\n    .WithPartitions(3)\n    .WithReplicationFactor(2)\n    .AsStream();                         // ✅ Stream/Table指定のみ許可\n```    \nこのビルダーは、Avroスキーマ生成時に高度な制御が必要な場合に限り使用される。\nただし、以下のメソッド呼び出しは設計原則違反となる。\n\n🚫 制限事項\nメソッド\t理由\n.ToTopic(\"...\")\tトピック名は [Topic] 属性で指定するため禁止\n.HasKey(...)\tキー定義は [Key] 属性に一本化されている\n.AsStream() / .AsTable()\t属性またはModelBuilderと重複可能。両方指定で一致しない場合はエラー\n\nこれらのメソッドは呼び出された場合に NotSupportedException をスローする設計とし、誤用を防止する。\n\n### 3.1 トピック (Kafka Topics)\n\n\n#### トピック定義\n```csharp\n// 属性によるマッピング\n[Topic(\"orders\", PartitionCount = 12, ReplicationFactor = 3)]\npublic class Order \n{\n    [Key]\n    public string OrderId { get; set; }\n    public string CustomerId { get; set; }\n    public decimal Amount { get; set; }\n    public DateTime OrderTime { get; set; }\n}\n\n// Fluent API\nmodelBuilder.Entity<Order>()\n    .WithPartitions(12)\n    .WithReplicationFactor(3);\n```\n\n#### トピック構成\n- パーティション設定: パーティション数、パーティショニング戦略\n- レプリケーション設定: レプリケーションファクター、ISRの最小数\n- 保持ポリシー: メッセージの保持期間、サイズ制限\n- 圧縮設定: トピックレベルの圧縮方式\n\n#### スキーマ管理\n- 自動スキーマ登録: POCOからAvroスキーマを生成し登録\n- 互換性設定: スキーマ互換性ポリシーの指定\n- スキーマ進化: スキーマバージョンの管理とマイグレーション\n\n#### トピック操作\n```csharp\n/ 型定義に基づく登録\nawait context.EnsureDeclaredAsync<Order>();\n\n// 型定義に基づく削除\nawait context.UndeclareAsync<Order>();\n```\n\n### 3.2 ストリーム (KSQL Streams)\n#### ストリーム定義の前提\n\nストリームは POCO に対して LINQ 式が適用されたときに動的に解釈され、生成される。\n\n#### 判定ルール\n\nPOCO（C#のエンティティ定義）に対してLINQ式が記述された場合、\nその型は \"ストリーム\" として解釈され、対応する CREATE STREAM 定義が自動生成されます。\n\nただし、以下のように GroupBy や Aggregate、Window を含む場合は CREATE TABLE（テーブル）として解釈されます。\n```csharp\n// ストリームとして解釈される例（AutoCommitがデフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// テーブルとして解釈される例（GroupBy を含む）\nmodelBuilder.Entity<Order>()\n    .Window(TumblingWindow.Of(TimeSpan.FromHours(1)))\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new HourlyStats \n    { \n        CustomerId = g.Key,\n        Hour = g.Window.Start,\n        OrderCount = g.Count() \n    });\n\n// 明示的にストリームとして扱う（GroupByがあっても）\nmodelBuilder.Entity<Order>()\n    .AsStream()\n    .GroupBy(o => o.Region)\n    .Select(g => new { g.Key });\n\n// 明示的にテーブルとして扱う\nmodelBuilder.Entity<Order>()\n    .AsTable()\n    .Select(o => new { o.CustomerId, o.Amount });\n```\n\nこのように modelBuilder.Entity<Order>() に対して LINQ が付くか否かで \"配信対象\"\nさらに LINQ の内容によって \"ストリーム\" か \"テーブル\" かを判別します。\n加えて、.AsStream() や .AsTable() を使用することで、意図的に解釈を上書きすることも可能です。\n\n#### コミット方式の指定\n\n購読処理（ForEachAsync）時の commit モードは、LINQ 定義末尾で明示的に設定します。\n```csharp\n// 自動コミット（デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n\n// 手動コミットを明示\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n```\n注意：購読時の commit モードは LINQ 実行時に切り替えることはできません。定義時に確定させる必要があります。\n\n### 3.3 テーブル (KSQL Tables)\n\nこのライブラリでは、LINQ 式が GroupBy や Aggregate を含み、テーブルと判定された場合、対応するトピックは 自動的に compact モードで作成 されます。\n\n開発者はコンパクションの有無を意識せず、通常の LINQ クエリ定義だけで正しく永続化特性を持ったトピックを扱えます。\n```csharp\nvar latestOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Select(g => new {\n        CustomerId = g.Key,\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n```\nこの例では CustomerId をキーとした最新の注文金額だけを保持するテーブルが作成され、その裏のトピックは compact となります。\n\n#### テーブル判定ルールと基本設計\nPOCO（C#のエンティティ定義）に対する LINQ 式の中で GroupBy, Aggregate, Window などの構文が含まれている場合、そのクエリは CREATE TABLE に相当する KSQL テーブルと解釈されます。これにより、ストリームとテーブルの判定が LINQ 構文の意味に基づいて一貫して行われます。\n\nまた、.AsTable() を明示的に呼び出すことで、意図的にテーブルとして扱うことも可能です。\n\n#### 集約操作\n```csharp\n// サマリ集計\nvar customerStats = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerStats \n    { \n        CustomerId = g.Key, \n        TotalAmount = g.Sum(o => o.Amount),\n        OrderCount = g.Count()\n    });\n\n// LATEST_BY_OFFSET\nvar latestCustomerOrders = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerLatestOrder\n    {\n        CustomerId = g.Key,\n        LatestOrderId = g.LatestByOffset(o => o.OrderId),\n        LatestOrderTime = g.LatestByOffset(o => o.OrderTime),\n        LatestAmount = g.LatestByOffset(o => o.Amount)\n    });\n\n// EARLIEST_BY_OFFSET\nvar firstTimeCustomers = context.Orders\n    .GroupBy(o => o.CustomerId)\n    .Aggregate(g => new CustomerFirstOrder\n    {\n        CustomerId = g.Key,\n        FirstOrderId = g.EarliestByOffset(o => o.OrderId),\n        FirstOrderTime = g.EarliestByOffset(o => o.OrderTime),\n        FirstAmount = g.EarliestByOffset(o => o.Amount)\n    });\n\n\n```\n#### テーブル結合（JOIN）\n\n```csharp\n// 単一キー結合\nvar query = from o in context.Orders\n            join c in context.Customers\n            on o.CustomerId equals c.CustomerId\n            select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 複合キー結合\nvar query2 = from o in context.Orders\n             join c in context.Customers\n             on new { o.CustomerId, o.Region } equals \n                new { c.CustomerId, c.Region }\n             select new { o.OrderId, c.CustomerName, o.Amount };\n\n// 3テーブル結合\nvar query3 = from o in context.Orders\n             join c in context.Customers on o.CustomerId equals c.CustomerId\n             join p in context.Products on o.ProductId equals p.ProductId\n             select new {\n                 o.OrderId,\n                 c.CustomerName,\n                 p.ProductName,\n                 o.Quantity,\n                 o.Amount\n             };\n\n```\n\n### 3.4 クエリと購読\n\n#### ストリーム定義とコミット方式の指定\n```csharp\n// modelBuilder による定義（自動コミット：デフォルト）\nmodelBuilder.Entity<Order>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId });\n// 自動コミットの購読処理（デフォルト）\nawait foreach (var order in context.Orders.ForEachAsync())\n{\n    Console.WriteLine($\"Received: {order.Value.OrderId}\");\n    // 自動でコミットされるため明示的な commit は不要\n}\n\n// modelBuilder による定義（手動コミット）\nmodelBuilder.Entity<HighValueOrder>()\n    .Where(o => o.Amount > 1000)\n    .Select(o => new { o.OrderId, o.CustomerId })\n    .WithManualCommit();\n\n// 手動コミット付きの購読処理\nawait foreach (var order in context.HighValueOrders.ForEachAsync())\n{\n    try\n    {\n        Console.WriteLine($\"Received: {order.Value.OrderId}\");\n        await order.CommitAsync();\n    }\n    catch\n    {\n        await order.NegativeAckAsync();\n    }\n}\n```\n\n## 4. POCO (Plain Old CLR Objects) の設計\n\n### 4.1 基本定義\n- シンプルなC#クラス: 特別な基底クラス不要\n- 標準的なプロパティ: 一般的な.NET型のサポート\n\n\n### 4.2 型のサポート\n\n以下はPOCOで使用可能な主なデータ型の一覧です：\n\n|データ型|説明|\n---|---\nint, long|整数型、KafkaではAvro/Protobuf経由でそのままマッピング可能\nfloat, double|浮動小数点数\ndecimal|高精度数値。[DecimalPrecision]で精度指定可能\nbool|真偽値\nstring|テキスト\nDateTime, DateTimeOffset|日時型。Kafkaへの送信時にUTC変換処理が入る\nGuid|一意識別子としてサポート\nshort|Kafkaでは int として扱われます。使用可能ですが、必要に応じて明示的なスキーマ変換を考慮してください。\nchar|Kafkaには直接の対応がなく、事実上非推奨です。1文字は string 型で表現することを推奨します。\n\n#### Decimal型の精度指定\n```csharp\n[DecimalPrecision(precision: 18, scale: 4)]\npublic decimal Amount { get; set; }\n```\n\n#### DateTime/DateTimeOffset\n```csharp\n// DateTimeOffset推奨（タイムゾーン情報保持）\npublic DateTimeOffset TransactionTime { get; set; }\n\n// または設定付きのDateTime\n[DateTimeFormat(Format = \"yyyy-MM-dd'T'HH:mm:ss.SSS\", Locale = \"en-US\")]\npublic DateTime OrderDate { get; set; }\n```\nKafkaにはタイムゾーンの概念がなく、すべての時刻はUTCとして扱われます。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。このフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。DateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。そのため、タイムゾーンを意識したビジネスロジックの記述が可能です。また、DateTime を使用しても、Kafka送信時には内部的に DateTimeOffset(Utc) に変換されるため、安全に運用可能です。このため、プロデューサとコンシューマが同一のタイムゾーン前提を共有していることが重要です。\n\nこのフレームワークは Kafka に不慣れな開発者でも安全に利用できるよう設計されています。\nDateTimeOffset を利用することで、開発者はタイムゾーン情報を保ったままアプリケーション開発ができ、Kafka との間の UTC 変換はフレームワークが吸収します。\nそのため、タイムゾーンを意識したビジネスロジックの記述が可能です。\n#### null許容性\n```csharp\n// C#標準の ?修飾子を使用\npublic int? OptionalQuantity { get; set; }\n```\n\n#### 数値型のデフォルト値\n```csharp\n[DefaultValue(10)]\npublic int Quantity { get; set; }\n```\n非nullableな数値プロパティ（例：int, double など）は、C#の仕様により初期化されていない場合でも自動的に 0 や 0.0 などの既定値が適用されます。Kafka送信時もこれらの値がそのまま使用されます。特別な初期化が不要なケースでは [DefaultValue] 属性は省略可能です。\n\n## 5. プロデュース操作\nこのセクションでは、Kafka にデータを送信（プロデュース）する際の基本的な操作方法とフレームワークが提供する抽象化手法について説明します。開発者は Kafka の複雑な設定を意識することなく、Entity Framework ライクな記述でストリームデータを扱うことができます。\n### 5.1 プロデューサー (データ送信)\nKafkaのリアルタイム性を維持するため、本フレームワークでは AddAsync によって即時にKafkaへ送信が行われます。\nEntity Frameworkのように SaveChangesAsync によってバッファを明示的にフラッシュする設計とは異なります。\nこのため、開発者は AddAsync を「送信操作」として扱うことを前提に実装してください。\n```csharp\n// 単一レコードのプロデュース\nawait context.Orders.AddAsync(new Order { OrderId = \"123\", Amount = 100 });\n\n```\nAddAsync を呼び出すことで、該当する Kafka トピックにイベントが送信されます。\n\n複数件のバッファリング送信や並列制御も内部で吸収されます\n\n### 5.3 トランザクション処理\nKafka は一部の操作に対して「プロデューサートランザクション」をサポートしています。ただし、ksqlDB 側ではトランザクション処理を前提としていないため、本フレームワークでは以下のような方針を採用します：\n\n明示的なトランザクション API は提供しない（例：BeginTransaction / CommitTransaction）\n\nKafka における「Exactly Once Semantics (EOS)」をサポートする構成の場合でも、アプリケーション側では操作単位の idempotency を保証してください。\n\n複数件の連続送信が必要な場合、アプリケーション側で逐次 AddAsync() を呼び出す実装で十分に高い信頼性を確保できます。\n\nこのフレームワークでは、Kafka のリアルタイムストリーム処理の思想に従い、永続化トランザクションよりも 即時性と可用性のバランスを優先しています。\n\n\n## 6. エラー処理とデータ品質\n\n### 6.1 エラー処理戦略\n```csharp\n// エラー処理ポリシーの設定\ncontext.Options.DeserializationErrorPolicy = ErrorPolicy.Skip;\n\n// エラーハンドリング付きストリーム処理\nvar processedOrders = context.Orders\n    .OnError(ErrorAction.Skip)  // エラーレコードをスキップ\n    .Map(order => ProcessOrder(order))\n    .WithRetry(3);  // 失敗時に3回リトライ\n```\n\n### 6.2 デッドレターキュー\nDLQ の設定は、エンティティ定義時に行います。以下のように modelBuilder.Entity<T>() の中で指定することで、対象のストリーム／テーブルごとに個別の DLQ を定義できます。\nDLQ トピック名は省略可能で、省略された場合は \"{EntityName}-dlq\" の形式で自動生成されます。\n```csharp\nmodelBuilder.Entity<Order>()\n    .WithDeadLetterQueue(); \n    // トピック名は \"orders-dlq\" のように自動生成されます\n```\nDLQ を設定することで、変換や送信に失敗したデータを指定トピックへ退避可能です。\n\nDLQ に送られたメッセージは後続で再処理やモニタリングの対象となります。\n\n### 6.3 スキーマフォーマットについて\n\n本フレームワークでは、Kafka のスキーマレジストリと連携するフォーマットとして Avro のみ をサポートしています。\n\nJSON Schema は扱いません（理由：データサイズ・速度・互換性管理の観点から）\n\nPOCO から Avro スキーマは自動生成され、初回登録 or 更新時にレジストリへ登録されます\n\nスキーマレジストリの互換性設定（BACKWARD, FULL など）に応じた開発を推奨します\n\n## 7. テーブル管理操作（開発・検証用途）\n本フレームワークでは、KSQL上に定義されるストリーム／テーブルの初期化・削除を、開発・検証用途に限り API として提供します。\n\n```csharp\nawait context.EnsureTableCreatedAsync<HourlyStats>();\nawait context.DropTableAsync(\"hourly_stats\");\n```\n注意:\nこれらの操作は 開発・CI/CD 環境での利用を前提 としており、本番環境での実行は推奨されません。\n本番では modelBuilder による明示的な定義と、デプロイ時のDDL管理が基本となります。\n\n\n## 8. リリース計画\n\n### フェーズ1: 基盤構築 (v0.1-v0.3)\n- トピックおよびストリーム定義 DSL\n- POCO ベースのデータ定義とマッピング\n- プロデュース / コンシューム操作の抽象化\n- Dead Letter Queue 対応\n\n\n### フェーズ2: 高度なストリーム処理 (v0.4-v0.6)\n- LINQ ベースのウィンドウ・集約処理\n- ストリーム / テーブルの明示的切り替え\n- スキーマ進化対応の検討\n\n### フェーズ3: 高度なデータ連携 (v0.7-v0.9)\n- JOIN処理のDSL化（複合キー対応含む）\n- テーブル定義と RocksDB 前提の読み取り最適化\n- エラー通知・メトリクス・DLQ監視基盤との連携\n\n### フェーズ4: エンタープライズ機能 (v1.0+)\n- 分散トレーシングとメトリクス\n- トランザクショナルメッセージング\n- マルチクラスタサポート\n\n## 9. アーキテクチャ概要\n本フレームワークは、Kafka／ksqlDB 環境における Entity Framework ライクな操作を実現するために、以下の主要レイヤーと責務をもって構成されます。\n### 9.1 レイヤー構成\n\n```\n+------------------------------+\n| アプリケーション層           |\n|------------------------------|\n| - コンシューマ購読処理       |\n| - LINQベースのDSL記述       |\n| - POCO定義（エンティティ）   |\n+------------------------------+\n            ↓\n+------------------------------+\n| DSL定義／マッピング層        |\n|------------------------------|\n| - modelBuilder によるDSL定義 |\n| - LINQの解釈とクエリ変換     |\n| - ストリーム／テーブル区別   |\n+------------------------------+\n            ↓\n+------------------------------+\n| コード解析・モデル構築層     |\n|------------------------------|\n| - POCO構造の解析              |\n| - Avroスキーマの自動生成     |\n| - スキーマレジストリへの登録 |\n| - トピック／DLQ名の解決       |\n+------------------------------+\n            ↓\n+------------------------------+\n| Kafka連携層（プロデュース／購読）|\n|------------------------------|\n| - Kafkaへの送信（AddAsync）   |\n| - ForEachAsyncによる購読処理 |\n| - DLQへのエラールーティング   |\n+------------------------------+\n            ↓\n+------------------------------+\n| KSQL操作層                   |\n|------------------------------|\n| - CREATE STREAM/TABLE生成    |\n| - JOIN / AGGREGATE の発行    |\n| - クエリ登録と監視           |\n+------------------------------+\n            ↓\n+------------------------------+\n| RocksDBキャッシュ層（KTable backing store） |\n|------------------------------|\n| - KTable/テーブル参照時にRocksDBでローカルキャッシュ\n| - 参照クエリは極力RocksDB経由で応答（遅延低減・パフォーマンス最適化）\n+------------------------------+\n\n```\n### 9.2 フォーマットポリシー\n\n本フレームワークでは Kafka との通信において Avro のみを正式サポート しています。\n\nJSON Schema はサポート対象外です（理由：サイズ効率・速度・互換性管理の明確性）。\n\nスキーマは自動生成され、スキーマレジストリに登録されます。\n\n### 9.3 補足\n\nスキーマレジストリの接続設定や互換性ルール（BACKWARD 等）は別途構成で指定。\n\nストリーム／テーブルの定義、DLQ設定、LINQ DSL、プロデュース／購読などの責務が明確に分離されており、将来的な拡張やプラガブルアーキテクチャが可能です。\n\n #### RocksDBキャッシュ設計思想\n\n 本フレームワークでは、KSQLのテーブル（KTable）参照時に、RocksDBをバックエンドストアとして自動利用し、参照クエリのパフォーマンスを最大化しています。\n\n - 通常の`.ToList()`や`.FirstOrDefault()`などの参照はRocksDBを経由し、ksqlDBやKafka本体への都度問い合わせを避けます。\n - RocksDB層はデフォルトで有効化。キャッシュサイズや永続化設定など詳細は将来的にFluent APIで拡張予定です。\n - この設計により、「大量データ参照でもレイテンシが大幅に低減」されます。\n - 詳細なパフォーマンス設計例はFAQ・運用ガイド参照。\n\n10.4 DIコンテナと初期化タイミング\n\n本フレームワークの利用においては、KafkaDbContext は DI コンテナを通じてスコープ管理されることを想定しています。\n\nDbContext のインスタンスが解決されると、内部的に OnModelCreating() が呼ばれ、LINQベースの DSL 定義が構築・解析されます。\n\nコンストラクタは軽量であり、DSL構文の構築のみを行います。\n\nKafkaやスキーマレジストリへの接続確認・リソース作成は、以下のように明示的に EnsureKafkaReadyAsync() を呼び出して実行します：\n\n```\npublic class KafkaInitializer\n{\n    private readonly KafkaDbContext _context;\n\n    public KafkaInitializer(KafkaDbContext context)\n    {\n        _context = context;\n    }\n\n    public async Task InitializeAsync()\n    {\n        await _context.EnsureKafkaReadyAsync();\n    }\n}\n\n```\n注意点：このタイミングで Schema Registry への通信や Kafka メタデータ取得処理が走るため、接続先が利用可能でない場合に例外が発生する可能性があります。\n\nそのため、KafkaDbContext 自体は軽量な構築とし、重い外部接続処理は明示的な初期化メソッドに切り出しています。\n\nEF と異なり Kafka OSS では「コードに基づいて Kafka 側の構造を生成する」ため、初期化を明示化することで、利用者の意図したタイミングでエラーを把握できる構造となっています。\n\nこの点を考慮し、Kafka 接続が不要な構文検証モードを別途用意することも検討されます（例：ValidateModelOnly=true オプション）。\n\nKafka接続不要な構文検証モードの価値\n\nこのモードには以下の利点があります：\n\nCI/CD での構文検証：Kafka や Schema Registry が起動していない環境でも LINQ DSL や POCO の定義が妥当かを自動チェック可能。\n\nKafka インフラ未構築でも開発可能：先に LINQ や POCO を定義し、Kafka が準備される前に開発が進行可能。\n\n安全な単体テスト：Kafka 接続なしでローカルテストが可能。\n\n学習コスト低減：Kafka 環境のセットアップを待たずに、DSL定義の学習・試行錯誤が可能。。\n\n\n## 11. Kafkaのcommit/DB commit・障害時の動作（DBエンジニア必読）\n\nKafkaのコンシューマアプリでは「オフセットcommit」と「DBのトランザクションcommit」は同じではありません。 特にDBエンジニア・テックリード層に多い勘違いとして、\\*\\*障害発生時には「前回commitしたオフセット」から“再度メッセージが流れてくる”\\*\\*という動作を理解しておく必要があります。\n\n### サンプル：障害発生時の「重複実行」イメージ\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    // 1. DBに書き込む\n    db.Save(msg.Value); // 例：OrdersテーブルにINSERT\n\n    // 2. Kafkaにオフセットcommit（\"ここまで処理済み\"を通知）\n    consumer.Commit(msg);\n}\n```\n\n#### ▼このときの「状態」例\n\n| 処理        | DB     | Kafkaオフセット | 備考                       |\n| --------- | ------ | ---------- | ------------------------ |\n| 初回実行      | 書き込み済み | commit済み   | 1回だけでOK                  |\n| commit前障害 | 書き込み済み | commit前    | **再起動後、同じmsgを再実行（DB重複）** |\n| commit後障害 | 書き込み済み | commit済み   | 以降は次のmsgから処理             |\n\n#### 【冪等化例：重複反映を防ぐパターン】\n\n```csharp\nforeach (var msg in consumer.Consume())\n{\n    if (!db.Exists(msg.Key))\n    {\n        db.Save(msg.Value);\n    }\n    consumer.Commit(msg);\n}\n```\n\n- こうすることで、**再実行されてもDBは一意に保たれる**（冪等性担保）\n\n### 解説\n\n- Kafkaのcommitは「オフセット管理」でありDBのcommitとは意味が違う\n- commit前の副作用は何度も再実行される前提で設計する\n- 特にDB系テックリードは「一意反映」と誤認しやすいので**冪等設計必須**\n- こうした違いを理解せずに設計すると「二重反映」「消えたデータ」問題に直結\n\n",
              "cloud_doc_url": null,
              "input_pointer": {
                "message_index": 6,
                "message_id": "2350f41d-d35e-46f8-9306-cc17c1a41d12",
                "file_index": null,
                "line_range_start": null,
                "line_range_end": null
              },
              "fff_metadata": null
            }
          ],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "gpt-4o",
          "parent_id": "2be40021-4250-4987-8b25-5928ab475743",
          "request_id": "954d8e17cb379d04-IAD",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "2be40021-4250-4987-8b25-5928ab475743",
      "children": []
    }
  },
  "current_node": "20b0b312-9495-45d0-9003-645ac7f925bb"
}